{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Info\n","\n","\n","Here I will develop the simple densely connect model which will serve as a baseline. The idea is to create a model that can train in about 10 minutes and that provides with a reasonable baseline for more complex models."]},{"cell_type":"markdown","metadata":{},"source":["# Version v1.0\n","\n","TODO:\n","\n","- napravit vector embedding sensor_id-a prema koordinatama sensora, a ne prema embed_dim. Tako ćeš imat samo 3 koordinate. Možeš svim tim vektorima oduzet centar mase. Pitanje: je li neutrino u datasetu nužno prolazi kroz ishodište?\n","- hendlat vrijeme kao kumulativnu varijablu? \"time (int): the time of the pulse in nanoseconds in the current event time window. The absolute time of a pulse has no relevance, and only the relative time with respect to other pulses within an event is of relevance.\"\n","- na kraju ti je dimenzija input vektora (B, T, 3 + 1 + 1), 3 za lokaciju senzora (xyz), jedan za naboj i jedan za kumulativno vrijeme (koliko je vremena prošlo od početka). Možda možeš dodat još i jednu dimenziju, a to je auxiliary, dakle to bi bilo (B, T, 6)\n","- It's very important to remove the center of mass from the points to correctly estimate the angles!\n"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:24.738619Z","iopub.status.busy":"2023-02-26T16:51:24.738235Z","iopub.status.idle":"2023-02-26T16:51:24.744168Z","shell.execute_reply":"2023-02-26T16:51:24.743034Z","shell.execute_reply.started":"2023-02-26T16:51:24.738588Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import math\n","import wandb\n","import gc"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:24.755044Z","iopub.status.busy":"2023-02-26T16:51:24.754771Z","iopub.status.idle":"2023-02-26T16:51:24.762258Z","shell.execute_reply":"2023-02-26T16:51:24.761275Z","shell.execute_reply.started":"2023-02-26T16:51:24.755019Z"},"trusted":true},"outputs":[],"source":["\n","LOG_WANDB = True\n","# hyperparameters\n","n_opt_distance=3000000 # number of optimizations for distance loss\n","n_opt_angular=0 # number of optimizations for angular loss\n","max_iters = n_opt_distance + n_opt_angular # number of iterations\n","change_data_each = 10 # change batch of data every change_batch_every steps\n","device =   'cuda' if torch.cuda.is_available() else 'cpu'\n","evaluate_every_step = 1024\n","eval_iters = 32 # number of batches to process for evaluation\n","\n","grad_clip = False # enable gradient clipping\n","grad_clip_val = 1e-8 # gradient clipping value\n","\n","## network hyperparameters\n","batch_size= 512\n","gradient_accumulation_steps = 512 // batch_size # 256 // batch_size # used to simulate larger batch sizes\n","learning_rate = 1e-6 * batch_size / gradient_accumulation_steps\n","block_size = 96 # maximum context length\n","n_embd = 128\n","n_layers = 3\n","num_heads = 8\n","dropout = 0.2\n","ffwd_scale = 4\n","# --------------------\n","## \n","num_bins = 64\n","\n","print_each = 100\n","print_model_each = 10000\n","\n","torch.manual_seed(1337);"]},{"cell_type":"markdown","metadata":{},"source":["# Load sensor geometry"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:24.774882Z","iopub.status.busy":"2023-02-26T16:51:24.772565Z","iopub.status.idle":"2023-02-26T16:51:24.788231Z","shell.execute_reply":"2023-02-26T16:51:24.787185Z","shell.execute_reply.started":"2023-02-26T16:51:24.774855Z"},"trusted":true},"outputs":[{"data":{"text/plain":["([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 5160)"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["df_sensor_geometry = pd.read_csv(\"../../sensor_geometry.csv\")\n","sensor_ids = sorted(list(set(df_sensor_geometry[\"sensor_id\"].to_list())))\n","sensor_ids[:10], len(sensor_ids)"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["# list train files in \"/home/ubuntu/neutrino/high-speed/data/train\" and test in \"/home/ubuntu/neutrino/high-speed/data/test\"\n","train_files = !ls /home/ubuntu/neutrino/high-speed/data/train\n","test_files = !ls /home/ubuntu/neutrino/high-speed/data/test"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["# add root path to train and test files\n","train_files = [\"/home/ubuntu/neutrino/high-speed/data/train/\" + f for f in train_files]\n","test_files = [\"/home/ubuntu/neutrino/high-speed/data/test/\" + f for f in test_files]"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["df = pd.read_parquet(test_files[0]).fillna(0)"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x_1</th>\n","      <th>y_1</th>\n","      <th>z_1</th>\n","      <th>t_1</th>\n","      <th>charge_1</th>\n","      <th>charge_clipped_1</th>\n","      <th>auxiliary_1</th>\n","      <th>has_event_1</th>\n","      <th>x_2</th>\n","      <th>y_2</th>\n","      <th>...</th>\n","      <th>x_96</th>\n","      <th>y_96</th>\n","      <th>z_96</th>\n","      <th>t_96</th>\n","      <th>charge_96</th>\n","      <th>charge_clipped_96</th>\n","      <th>auxiliary_96</th>\n","      <th>has_event_96</th>\n","      <th>azimuth</th>\n","      <th>zenith</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.49130</td>\n","      <td>-0.38098</td>\n","      <td>0.45830</td>\n","      <td>0.414312</td>\n","      <td>0.4125</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.02374</td>\n","      <td>0.35838</td>\n","      <td>...</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.455179</td>\n","      <td>1.385139</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.72200</td>\n","      <td>-0.84566</td>\n","      <td>0.45436</td>\n","      <td>0.375875</td>\n","      <td>0.3875</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.60682</td>\n","      <td>0.67128</td>\n","      <td>...</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.182545</td>\n","      <td>1.073292</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.10852</td>\n","      <td>0.58594</td>\n","      <td>-0.21042</td>\n","      <td>0.370937</td>\n","      <td>0.8125</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.10852</td>\n","      <td>0.58594</td>\n","      <td>...</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4.812856</td>\n","      <td>2.279083</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.13340</td>\n","      <td>0.55384</td>\n","      <td>-0.74046</td>\n","      <td>0.370250</td>\n","      <td>0.5875</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>-0.66960</td>\n","      <td>-0.84900</td>\n","      <td>...</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5.207917</td>\n","      <td>0.722861</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.06250</td>\n","      <td>-0.14586</td>\n","      <td>-0.45844</td>\n","      <td>0.388062</td>\n","      <td>0.5875</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.06250</td>\n","      <td>-0.14586</td>\n","      <td>...</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.723178</td>\n","      <td>2.829807</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2719</th>\n","      <td>-0.46990</td>\n","      <td>0.28088</td>\n","      <td>-0.36154</td>\n","      <td>0.369437</td>\n","      <td>0.3625</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.11440</td>\n","      <td>-0.21104</td>\n","      <td>...</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6.198101</td>\n","      <td>2.676218</td>\n","    </tr>\n","    <tr>\n","      <th>2720</th>\n","      <td>0.66006</td>\n","      <td>0.25440</td>\n","      <td>-0.70034</td>\n","      <td>0.376000</td>\n","      <td>0.5375</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.31788</td>\n","      <td>-0.69046</td>\n","      <td>...</td>\n","      <td>0.39006</td>\n","      <td>0.25118</td>\n","      <td>-0.49416</td>\n","      <td>1.134937</td>\n","      <td>0.4375</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.774357</td>\n","      <td>0.124723</td>\n","    </tr>\n","    <tr>\n","      <th>2721</th>\n","      <td>-0.31246</td>\n","      <td>0.08674</td>\n","      <td>-0.53020</td>\n","      <td>0.370937</td>\n","      <td>0.3125</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>-0.46990</td>\n","      <td>0.28088</td>\n","      <td>...</td>\n","      <td>-0.37996</td>\n","      <td>0.51484</td>\n","      <td>0.08358</td>\n","      <td>1.063562</td>\n","      <td>0.5375</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2.008464</td>\n","      <td>0.902644</td>\n","    </tr>\n","    <tr>\n","      <th>2722</th>\n","      <td>0.26406</td>\n","      <td>0.40596</td>\n","      <td>-0.45832</td>\n","      <td>0.370250</td>\n","      <td>0.5125</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>-0.02194</td>\n","      <td>0.01344</td>\n","      <td>...</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.012985</td>\n","      <td>1.496544</td>\n","    </tr>\n","    <tr>\n","      <th>2723</th>\n","      <td>-0.46990</td>\n","      <td>0.28088</td>\n","      <td>0.52354</td>\n","      <td>0.386375</td>\n","      <td>0.4375</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.04422</td>\n","      <td>1.01900</td>\n","      <td>...</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.0000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5.518599</td>\n","      <td>1.375372</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2724 rows × 770 columns</p>\n","</div>"],"text/plain":["          x_1      y_1      z_1       t_1  charge_1  charge_clipped_1  \\\n","0    -0.49130 -0.38098  0.45830  0.414312    0.4125                 0   \n","1     0.72200 -0.84566  0.45436  0.375875    0.3875                 0   \n","2     0.10852  0.58594 -0.21042  0.370937    0.8125                 0   \n","3    -0.13340  0.55384 -0.74046  0.370250    0.5875                 0   \n","4     0.06250 -0.14586 -0.45844  0.388062    0.5875                 0   \n","...       ...      ...      ...       ...       ...               ...   \n","2719 -0.46990  0.28088 -0.36154  0.369437    0.3625                 0   \n","2720  0.66006  0.25440 -0.70034  0.376000    0.5375                 0   \n","2721 -0.31246  0.08674 -0.53020  0.370937    0.3125                 0   \n","2722  0.26406  0.40596 -0.45832  0.370250    0.5125                 0   \n","2723 -0.46990  0.28088  0.52354  0.386375    0.4375                 0   \n","\n","      auxiliary_1  has_event_1      x_2      y_2  ...     x_96     y_96  \\\n","0               1            1  0.02374  0.35838  ...  0.00000  0.00000   \n","1               1            1  0.60682  0.67128  ...  0.00000  0.00000   \n","2               1            1  0.10852  0.58594  ...  0.00000  0.00000   \n","3               1            1 -0.66960 -0.84900  ...  0.00000  0.00000   \n","4               1            1  0.06250 -0.14586  ...  0.00000  0.00000   \n","...           ...          ...      ...      ...  ...      ...      ...   \n","2719            1            1  0.11440 -0.21104  ...  0.00000  0.00000   \n","2720            1            1  0.31788 -0.69046  ...  0.39006  0.25118   \n","2721            1            1 -0.46990  0.28088  ... -0.37996  0.51484   \n","2722            1            1 -0.02194  0.01344  ...  0.00000  0.00000   \n","2723            1            1  0.04422  1.01900  ...  0.00000  0.00000   \n","\n","         z_96      t_96  charge_96  charge_clipped_96  auxiliary_96  \\\n","0     0.00000  0.000000     0.0000                  0             0   \n","1     0.00000  0.000000     0.0000                  0             0   \n","2     0.00000  0.000000     0.0000                  0             0   \n","3     0.00000  0.000000     0.0000                  0             0   \n","4     0.00000  0.000000     0.0000                  0             0   \n","...       ...       ...        ...                ...           ...   \n","2719  0.00000  0.000000     0.0000                  0             0   \n","2720 -0.49416  1.134937     0.4375                  0             1   \n","2721  0.08358  1.063562     0.5375                  0             1   \n","2722  0.00000  0.000000     0.0000                  0             0   \n","2723  0.00000  0.000000     0.0000                  0             0   \n","\n","      has_event_96   azimuth    zenith  \n","0                0  1.455179  1.385139  \n","1                0  1.182545  1.073292  \n","2                0  4.812856  2.279083  \n","3                0  5.207917  0.722861  \n","4                0  3.723178  2.829807  \n","...            ...       ...       ...  \n","2719             0  6.198101  2.676218  \n","2720             1  2.774357  0.124723  \n","2721             1  2.008464  0.902644  \n","2722             0  0.012985  1.496544  \n","2723             0  5.518599  1.375372  \n","\n","[2724 rows x 770 columns]"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"data":{"text/plain":["(2724,\n"," array([[-0.4913    , -0.38098   ,  0.4583    , ...,  0.        ,\n","          1.45517938,  1.38513897],\n","        [ 0.722     , -0.84566   ,  0.45436   , ...,  0.        ,\n","          1.18254459,  1.07329169],\n","        [ 0.10852   ,  0.58594   , -0.21042   , ...,  0.        ,\n","          4.81285553,  2.27908285],\n","        ...,\n","        [-0.31246   ,  0.08674   , -0.5302    , ...,  1.        ,\n","          2.00846445,  0.90264441],\n","        [ 0.26406   ,  0.40596   , -0.45832   , ...,  0.        ,\n","          0.01298527,  1.49654403],\n","        [-0.4699    ,  0.28088   ,  0.52354   , ...,  0.        ,\n","          5.51859887,  1.37537228]]))"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["x = df.values\n","len(x), x"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[],"source":["x2 = np.array(x[0])\n","y = x2[-2:]\n","x2 = x2[:-2]"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"data":{"text/plain":["(96, 3)"]},"execution_count":105,"metadata":{},"output_type":"execute_result"}],"source":["np.reshape(x2, (96, 8))[:,:3].shape"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["df=df.iloc[0]"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[],"source":["# def get_el():\n","#     x = df.iloc[0].values\n","#     x = np.array(x[:-2])\n","#     x = np.reshape(x, (len(x)//8, 8))\n","#     x = np.array(x, dtype=np.float32)\n","#     x[np.isnan(x)] = 0\n","#     return x\n","    \n","# # %timeit get_el()\n","# # 353 µs ± 30.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["# x = get_el()"]},{"cell_type":"code","execution_count":109,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:24.795375Z","iopub.status.busy":"2023-02-26T16:51:24.795089Z","iopub.status.idle":"2023-02-26T16:51:24.823030Z","shell.execute_reply":"2023-02-26T16:51:24.822182Z","shell.execute_reply.started":"2023-02-26T16:51:24.795351Z"},"trusted":true},"outputs":[],"source":["class EventDataLoader:\n","    def __init__(self):\n","        self.change_data_each = change_data_each\n","        self.data_files = {\n","            'train': train_files,\n","            'test': test_files,\n","        }\n","        self.events = {\n","            'train': pd.read_parquet(train_files[0]).fillna(0).values,\n","            'test': pd.read_parquet(test_files[0]).fillna(0).values,\n","        }\n","        # self.remove_nans('train')\n","        # self.remove_nans('test')\n","        self.batch_size = batch_size\n","        \n","        \n","        self.counter=0 # used to keep track of the current batch\n","    \n","    def refresh_batch(self):\n","        self.counter = 0\n","        random_file_train = random.choice(self.data_files['train'])\n","        random_file_test = random.choice(self.data_files['test'])\n","        self.events = {\n","            'train': pd.read_parquet(random_file_train).fillna(0).values,\n","            # 'test': pd.read_parquet(random_file_test).fillna(0).values,\n","        }\n","        # self.remove_nans('train')\n","        # self.remove_nans('test')\n","    \n","    # def remove_nans(self, split):\n","    #     # convert nan to zero\n","    #     self.events[split] = self.events[split].fillna(0)\n","        \n","    def get_random_el(self, split):\n","        randint = random.randint(0, len(self.events[split])-1)\n","        x = self.events[split][randint]\n","        y = np.array(x[-2:], dtype=np.float32)\n","        x = np.array(x[:-2])\n","        x = np.reshape(x, (96, 8))\n","        x = np.array(x, dtype=np.float32)\n","        # x_1\ty_1\tz_1\tt_1\tcharge_1\tcharge_clipped_1\tauxiliary_1\thas_event_1\n","        xyz = x[:,:3]\n","        # xyz_avg is xyz subtracted by the center of mass along each axis. use keepdims=True to keep the shape\n","        t = x[:,3]\n","        charge = x[:,4]\n","        charge_clipped = x[:,5]\n","        auxiliary = x[:,6]\n","        has_event = x[:,7]\n","        xyz_avg = xyz - np.mean(xyz, axis=0, keepdims=True)\n","        xyz_avg[np.where(has_event<0.5)] = 0\n","        \n","        x = {\n","            'xyz': xyz,\n","            'xyz_avg': xyz_avg,\n","            't': t,\n","            'charge': charge,\n","            'charge_clipped': charge_clipped,\n","            'auxiliary': auxiliary,\n","            'has_event': has_event\n","        }\n","        \n","        return x, y\n","\n","    \n","    def get_xy(self, split):\n","        \n","        \n","        preprocessed_data = [self.get_random_el(split) for _ in range(self.batch_size)]\n","        \n","        xyz_avg_batch = torch.stack([torch.from_numpy(x['xyz_avg']) for x, _ in preprocessed_data])\n","        xyz_batch = torch.stack([torch.from_numpy(x['xyz']) for x, _ in preprocessed_data])\n","        time_batch = torch.stack([torch.from_numpy(x['t']) for x, _ in preprocessed_data])\n","        charge_batch = torch.stack([torch.from_numpy(x['charge']) for x, _ in preprocessed_data])\n","        charge_clipped_batch = torch.stack([torch.from_numpy(x['charge_clipped']) for x, _ in preprocessed_data])\n","        auxiliary_batch = torch.stack([torch.from_numpy(x['auxiliary']) for x, _ in preprocessed_data])\n","        has_event_batch = torch.stack([torch.from_numpy(x['has_event']) for x, _ in preprocessed_data])\n","        y = torch.stack([torch.from_numpy(y) for _, y in preprocessed_data])\n","        \n","        # send to device\n","        xyz_avg_batch = xyz_avg_batch.to(device)\n","        xyz_batch = xyz_batch.to(device)\n","        time_batch = time_batch.to(device)\n","        charge_batch = charge_batch.to(device)\n","        charge_clipped_batch = charge_clipped_batch.to(device)\n","        auxiliary_batch = auxiliary_batch.to(device)\n","        has_event_batch = has_event_batch.to(device)\n","        y = y.to(device)\n","        \n","        \n","        \n","        X = {\n","            \"xyz_avg\": xyz_avg_batch,\n","            \"xyz\": xyz_batch,\n","            \"time\": time_batch,\n","            \"charge\": charge_batch,\n","            \"charge_clipped\": charge_clipped_batch,\n","            \"auxiliary\": auxiliary_batch,\n","            \"has_event\": has_event_batch,\n","        }\n","        \n","        self.counter += 1\n","        if self.counter == self.change_data_each:\n","            self.refresh_batch()\n","            self.counter = 0\n","        \n","        return X, y\n"]},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:24.834706Z","iopub.status.busy":"2023-02-26T16:51:24.834452Z","iopub.status.idle":"2023-02-26T16:51:30.731177Z","shell.execute_reply":"2023-02-26T16:51:30.730192Z","shell.execute_reply.started":"2023-02-26T16:51:24.834683Z"},"trusted":true},"outputs":[],"source":["data_loader = EventDataLoader()"]},{"cell_type":"code","execution_count":111,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:30.733363Z","iopub.status.busy":"2023-02-26T16:51:30.732988Z","iopub.status.idle":"2023-02-26T16:51:31.063716Z","shell.execute_reply":"2023-02-26T16:51:31.062806Z","shell.execute_reply.started":"2023-02-26T16:51:30.733328Z"},"trusted":true},"outputs":[],"source":["X, y = data_loader.get_xy('train')"]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([64, 96, 3])"]},"execution_count":112,"metadata":{},"output_type":"execute_result"}],"source":["X['xyz_avg'].shape"]},{"cell_type":"code","execution_count":113,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:31.069909Z","iopub.status.busy":"2023-02-26T16:51:31.067698Z","iopub.status.idle":"2023-02-26T16:51:31.083646Z","shell.execute_reply":"2023-02-26T16:51:31.082703Z","shell.execute_reply.started":"2023-02-26T16:51:31.069870Z"},"trusted":true},"outputs":[{"data":{"text/plain":["dict_keys(['xyz_avg', 'xyz', 'time', 'charge', 'charge_clipped', 'auxiliary', 'has_event'])"]},"execution_count":113,"metadata":{},"output_type":"execute_result"}],"source":["X.keys()"]},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[{"data":{"text/plain":["0.017453292519943295"]},"execution_count":114,"metadata":{},"output_type":"execute_result"}],"source":["# 1 in angles\n","1*np.pi/180"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([2.8887, 0.7663, 2.9211, 1.9787, 3.0344, 4.7348, 3.8046, 5.2838, 4.6686,\n","        1.1296, 1.7708, 2.9311, 3.1145, 4.9343, 1.6188, 1.5712, 6.1546, 6.0089,\n","        2.7829, 0.3744, 4.8138, 4.5212, 3.3586, 6.2285, 4.3045, 3.2437, 2.5533,\n","        0.7459, 0.9430, 5.1522, 4.7174, 5.1731, 2.6123, 2.6555, 4.6598, 3.8697,\n","        4.7560, 2.7514, 4.1510, 3.7210, 5.7034, 2.1410, 4.0169, 2.6019, 1.5396,\n","        0.1706, 5.3853, 3.2267, 4.8758, 6.1277, 0.3114, 2.0254, 4.8009, 1.2611,\n","        1.9178, 0.9220, 6.2379, 2.2223, 0.7368, 0.0727, 3.0151, 5.5387, 2.9159,\n","        4.7885], device='cuda:0')"]},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":["y[:,0]"]},{"cell_type":"code","execution_count":116,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[ 0.4617,  0.0026,  0.8669],\n","        [-0.5542,  0.5393,  0.4866],\n","        [-0.4393, -0.9777, -0.9875],\n","        [ 0.4617,  0.0026, -0.1203],\n","        [ 0.0967,  0.4228, -0.6685],\n","        [ 1.2257,  0.4063,  0.6085],\n","        [ 0.2540,  0.2291, -0.0571],\n","        [ 0.4219,  0.6955, -0.8519],\n","        [ 0.2869,  0.1186, -0.6330],\n","        [-0.3281, -0.0836,  0.8375],\n","        [-0.3281, -0.0836,  0.8375],\n","        [-0.3281, -0.0836,  0.8034],\n","        [-0.3281, -0.0836,  0.8034],\n","        [-0.3281, -0.0836,  0.8715],\n","        [-0.3281, -0.0836,  0.7694],\n","        [-0.3969,  0.3453,  0.7908],\n","        [ 0.7499,  0.9919,  0.2574],\n","        [-0.4183, -0.3166,  0.4532],\n","        [-0.7539, -0.5901,  0.2452],\n","        [-0.7539, -0.5901,  0.2452],\n","        [-0.5758, -0.1224, -0.5708],\n","        [-0.7539, -0.5901,  0.1430],\n","        [-0.7539, -0.5901,  0.1430],\n","        [-0.7539, -0.5901,  0.1090],\n","        [-0.7539, -0.5901,  0.1430],\n","        [-0.7539, -0.5901,  0.3132],\n","        [ 0.2540,  0.2291,  0.5557],\n","        [ 0.8161, -0.1199,  0.5575],\n","        [-0.5542,  0.5393, -0.2282],\n","        [-0.6649, -0.3560, -0.1274],\n","        [-0.0136, -0.4706,  0.4164],\n","        [ 0.0967,  0.4228, -0.6685],\n","        [-0.2598, -0.5112,  0.6495],\n","        [ 0.6373, -0.5871, -0.7443],\n","        [ 0.1355, -0.0814, -0.4335],\n","        [ 0.2177, -0.0688, -1.0096],\n","        [ 0.2177, -0.0688, -1.0096],\n","        [ 0.4617,  0.0026, -0.0863],\n","        [-0.5966, -0.7846,  0.2131],\n","        [ 0.8377,  0.5422,  0.1750],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000]], device='cuda:0')"]},"execution_count":116,"metadata":{},"output_type":"execute_result"}],"source":["X['xyz_avg'][0]"]},{"cell_type":"markdown","metadata":{},"source":["# Angular Loss function"]},{"cell_type":"code","execution_count":117,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:31.089962Z","iopub.status.busy":"2023-02-26T16:51:31.089645Z","iopub.status.idle":"2023-02-26T16:51:31.103057Z","shell.execute_reply":"2023-02-26T16:51:31.102096Z","shell.execute_reply.started":"2023-02-26T16:51:31.089933Z"},"trusted":true},"outputs":[],"source":["def angular_dist_score(az_true, zen_true, az_pred, zen_pred):\n","    '''\n","    calculate the MAE of the angular distance between two directions.\n","    The two vectors are first converted to cartesian unit vectors,\n","    and then their scalar product is computed, which is equal to\n","    the cosine of the angle between the two vectors. The inverse \n","    cosine (arccos) thereof is then the angle between the two input vectors\n","    \n","    Parameters:\n","    -----------\n","    \n","    az_true : float (or array thereof)\n","        true azimuth value(s) in radian\n","    zen_true : float (or array thereof)\n","        true zenith value(s) in radian\n","    az_pred : float (or array thereof)\n","        predicted azimuth value(s) in radian\n","    zen_pred : float (or array thereof)\n","        predicted zenith value(s) in radian\n","    \n","    Returns:\n","    --------\n","    \n","    dist : float\n","        mean over the angular distance(s) in radian\n","    '''\n","    \n","    if not (torch.all(torch.isfinite(az_true))  and\n","            torch.all(torch.isfinite(zen_true)) and\n","            torch.all(torch.isfinite(az_pred)) and\n","            torch.all(torch.isfinite(zen_pred))\n","           ):\n","        raise ValueError(\"All arguments must be finite\")\n","    \n","    # pre-compute all sine and cosine values\n","    sa1 = torch.sin(az_true)\n","    ca1 = torch.cos(az_true)\n","    sz1 = torch.sin(zen_true)\n","    cz1 = torch.cos(zen_true)\n","    \n","    sa2 = torch.sin(az_pred)\n","    ca2 = torch.cos(az_pred)\n","    sz2 = torch.sin(zen_pred)\n","    cz2 = torch.cos(zen_pred)\n","    \n","    # scalar product of the two cartesian vectors (x = sz*ca, y = sz*sa, z = cz)\n","    scalar_prod = sz1*sz2*(ca1*ca2 + sa1*sa2) + (cz1*cz2)\n","    \n","    # scalar product of two unit vectors is always between -1 and 1, this is against nummerical instability\n","    # that might otherwise occure from the finite precision of the sine and cosine functions\n","    scalar_prod =  torch.clamp(scalar_prod, -1, 1)\n","    \n","    # convert back to an angle (in radian)\n","\n","    return torch.abs(torch.acos(scalar_prod))"]},{"cell_type":"code","execution_count":118,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:31.108354Z","iopub.status.busy":"2023-02-26T16:51:31.105983Z","iopub.status.idle":"2023-02-26T16:51:31.123390Z","shell.execute_reply":"2023-02-26T16:51:31.122432Z","shell.execute_reply.started":"2023-02-26T16:51:31.108319Z"},"trusted":true},"outputs":[],"source":["# estimates the loss over eval_iters batches.\n","@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'test']:\n","        losses_distance = []\n","        losses_angular = []\n","        for k in range(eval_iters):\n","            X, y = data_loader.get_xy(split)\n","            (x, loss), (theta, phi, loss_angular) = model(X, y)\n","            losses_distance.append(loss.detach().cpu().numpy())\n","            losses_angular.append(loss_angular.detach().cpu().numpy())\n","        out[split] = {}\n","        out[split]['distance'] = np.average(losses_distance)\n","        out[split]['angular'] = np.average(losses_angular)\n","    model.train()\n","    return out"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[],"source":["class ResidualLSTM(nn.Module):\n","    \n","    def __init__(self, d_model):\n","        super(ResidualLSTM, self).__init__()\n","        self.LSTM=nn.LSTM(d_model, d_model, num_layers=1, bidirectional=True)\n","        self.linear1=nn.Linear(d_model*2, d_model*4)\n","        self.linear2=nn.Linear(d_model*4, d_model)\n","        \n","\n","            \n","    def forward(self, x):\n","        res=x\n","        x, _ = self.LSTM(x)\n","        x=F.relu(self.linear1(x))\n","        x=self.linear2(x)\n","        x=res+x\n","        return x\n","    \n","    \n","class SAKTModel(nn.Module):\n","    \n","    \n","    \n","    def _init_weights(self, module):\n","        \n","        init_std = 0.05\n","        \n","        if isinstance(module, nn.Linear):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=init_std)\n","            if module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","    \n","    \n","    def __init__(self, nout, n_embd=128,  nlayers=2, rnnlayers=3,\n","    dropout=0.1, nheads=8):\n","        super(SAKTModel, self).__init__()\n","        self.n_embd = n_embd\n","        self.pos_encoder = nn.ModuleList([ResidualLSTM(n_embd) for i in range(rnnlayers)])\n","        \n","        self.pos_encoder_dropout = nn.Dropout(dropout)\n","        \n","        self.embedding = nn.Linear(11, n_embd)\n","        self.layer_normal = nn.LayerNorm(n_embd)\n","        encoder_layers = [nn.TransformerEncoderLayer(n_embd, nheads, n_embd*4, dropout) for i in range(nlayers)]\n","        conv_layers = [nn.Conv1d(n_embd,n_embd,(nlayers-i)*2-1,stride=1,padding=0) for i in range(nlayers)]\n","        deconv_layers = [nn.ConvTranspose1d(n_embd,n_embd,(nlayers-i)*2-1,stride=1,padding=0) for i in range(nlayers)]\n","        layer_norm_layers = [nn.LayerNorm(n_embd) for i in range(nlayers)]\n","        layer_norm_layers2 = [nn.LayerNorm(n_embd) for i in range(nlayers)]\n","        self.transformer_encoder = nn.ModuleList(encoder_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers)\n","        self.layer_norm_layers = nn.ModuleList(layer_norm_layers)\n","        self.layer_norm_layers2 = nn.ModuleList(layer_norm_layers2)\n","        self.deconv_layers = nn.ModuleList(deconv_layers)\n","        self.nheads = nheads\n","        self.pred = nn.Linear(n_embd, nout)\n","\n","        self.apply(self._init_weights)\n","            \n","\n","    def forward(self, numerical_features):\n","        B, T, C = numerical_features.shape\n","        x=self.embedding(numerical_features.view(B*T, C)).view(B, T, self.n_embd)\n","        \n","        x = x.permute(1, 0, 2)\n","        for lstm in self.pos_encoder:\n","            lstm.LSTM.flatten_parameters()\n","            x=lstm(x)\n","\n","        x = self.pos_encoder_dropout(x)\n","        x = self.layer_normal(x)\n","\n","\n","\n","        for conv, transformer_layer, layer_norm1, layer_norm2, deconv in zip(self.conv_layers,\n","                                                               self.transformer_encoder,\n","                                                               self.layer_norm_layers,\n","                                                               self.layer_norm_layers2,\n","                                                               self.deconv_layers):\n","            #LXBXC to BXCXL\n","            res=x\n","            x=F.relu(conv(x.permute(1,2,0)).permute(2,0,1))\n","            x=layer_norm1(x)\n","            x=transformer_layer(x)\n","            x=F.relu(deconv(x.permute(1,2,0)).permute(2,0,1))\n","            x=layer_norm2(x)\n","            x=res+x\n","\n","        x = x.permute(1, 0, 2)\n","\n","        output = self.pred(x)\n","        output = output.squeeze(-1)\n","        \n","        # (B, T, C) -> (B, C)\n","        output = output[:, -1, :]\n","        output = F.softmax(output, dim=1)\n","        return output"]},{"cell_type":"code","execution_count":166,"metadata":{},"outputs":[],"source":["class NeutrinoDetection(nn.Module):\n","    def __init__(self):\n","        super(NeutrinoDetection, self).__init__()\n","        self.model_theta = SAKTModel(nout=num_bins, n_embd=n_embd,  nlayers=2, rnnlayers=3, dropout=dropout, nheads=num_heads).to(device)\n","        self.model_phi = SAKTModel(nout=num_bins, n_embd=n_embd,  nlayers=2, rnnlayers=3, dropout=dropout, nheads=num_heads).to(device)\n","        \n","        \n","        \n","\n","    def forward(self, X, targets=None):\n","        \n","        xyz_avg, xyz, time, charge, charge_clipped, auxiliary, has_event = X[\"xyz_avg\"], X[\"xyz\"], X[\"time\"], X[\"charge\"], X[\"charge_clipped\"], X[\"auxiliary\"], X[\"has_event\"]\n","        \n","        x = torch.cat([xyz_avg, xyz, time.unsqueeze(-1), charge.unsqueeze(-1), charge_clipped.unsqueeze(-1), auxiliary.unsqueeze(-1), has_event.unsqueeze(-1)], dim=-1)\n","        \n","        theta_probas = self.model_theta(x)\n","        phi_probas = self.model_phi(x)\n","        \n","        \n","        theta_pred = np.pi * torch.argmax(theta_probas, dim=1) / num_bins # (B)\n","        phi_pred = 2 * np.pi * torch.argmax(phi_probas, dim=1) / num_bins # (B)\n","        \n","        # define the bin edges for the ordinal labels\n","        # bin_edges = torch.linspace(0, 1, num_bins+1)[1:-1].to(device)\n","        \n","        # cumprods_theta = torch.cumprod(theta_probas > 0.5, dim=1)\n","        # theta_pred = (torch.sum(cumprods_theta, dim=1) - 1) * np.pi / num_bins # (B)\n","        # cumprods_phi = torch.cumprod(phi_probas > 0.5, dim=1)\n","        # phi_pred = (torch.sum(cumprods_phi, dim=1) - 1) * 2*np.pi / num_bins # (B)\n","        \n","        if targets is None:\n","            loss = None\n","            loss_angular = None\n","        else: \n","            # Get the angle theta and phi from the 3D vector\n","            phi_target = targets[:, 0]\n","            theta_target = targets[:, 1]\n","            \n","            \n","            \n","            losses_angular = angular_dist_score(phi_target, theta_target, phi_pred, theta_pred)\n","            # losses_angular = angular_dist_score(phi_target, theta_target, phi, theta)\n","            # loss_angular = torch.sum(event_size * losses_angular) / torch.sum(event_size)\n","            loss_angular = torch.mean(losses_angular)\n","            \n","            \n","            \n","            \n","            # construct the phi_target_probability and theta_target_probability: these are one-hot vectors with the same shape as phi_probas and theta_probas, with 1 at the position of \n","            theta_target = theta_target / np.pi\n","            theta_target = theta_target * num_bins\n","            theta_target = theta_target.long()\n","            theta_target = torch.nn.functional.one_hot(theta_target, num_classes=num_bins)\n","            \n","            phi_target = phi_target / (2*np.pi)\n","            phi_target = phi_target * num_bins\n","            phi_target = phi_target.long()\n","            phi_target = torch.nn.functional.one_hot(phi_target, num_classes=num_bins)\n","            \n","            \n","\n","            # loss is sum of the cross entropy of the predicted probabilities and the target probabilities\n","            eps = 1e-8\n","            loss_theta = torch.mean(-torch.sum(torch.log(theta_probas+eps)*theta_target, axis=-1))\n","            loss_phi = torch.mean(-torch.sum(torch.log(phi_probas+eps)*phi_target, axis=-1))\n","            loss = loss_theta + loss_phi\n","            \n","            \n","\n","            # # construct the theta_target_probability and phi_target_probability as ordinal targets\n","            # theta_target_bins = torch.bucketize(theta_target, bin_edges).to(device)\n","            # theta_target_probability = torch.zeros((len(theta_target), num_bins), dtype=torch.float32)\n","            # for i, bin_idx in enumerate(theta_target_bins):\n","            #     theta_target_probability[i, :bin_idx] = 1\n","\n","            # phi_target_bins = torch.bucketize(phi_target, bin_edges).to(device)\n","            # phi_target_probability = torch.zeros((len(phi_target), num_bins), dtype=torch.float32)\n","            # for i, bin_idx in enumerate(phi_target_bins):\n","            #     phi_target_probability[i, :bin_idx] = 1\n","\n","            # # send to device\n","            # theta_target_probability = theta_target_probability.to(device)\n","            # phi_target_probability = phi_target_probability.to(device)\n","            \n","            # # compute the ordinal loss\n","            # eps = 1e-8\n","            # loss_theta = torch.mean(-torch.sum(torch.log(torch.cat((theta_probas, 1-theta_probas), dim=-1)+eps) * torch.cat((theta_target_probability, 1-theta_target_probability), dim=-1), axis=-1))\n","            # loss_phi = torch.mean(-torch.sum(torch.log(torch.cat((phi_probas, 1-phi_probas), dim=-1)+eps) * torch.cat((phi_target_probability, 1-phi_target_probability), dim=-1), axis=-1))\n","            # loss = loss_theta + loss_phi\n","\n","\n","            \n","            \n","            \n","        \n","        return (x, loss), (theta_pred, phi_pred, loss_angular)\n","        "]},{"cell_type":"code","execution_count":167,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3.912832 M parameters\n"]}],"source":["model = NeutrinoDetection()\n","\n","# load /home/ubuntu/neutrino/high-speed/m11-lstm/model-best-96b.pth\n","model.load_state_dict(torch.load('model-best-96b.pth'), strict=False)\n","model = model.to(device)\n","\n","\n","print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # freeze all layers except those that contain \"pred.\" in the name\n","# for name, param in model.named_parameters():\n","#     if \"pred\" not in name:\n","#         param.requires_grad = False"]},{"cell_type":"code","execution_count":163,"metadata":{},"outputs":[],"source":["# X, y = data_loader.get_xy('train')\n","# x = model(X)"]},{"cell_type":"code","execution_count":123,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:31.128414Z","iopub.status.busy":"2023-02-26T16:51:31.127131Z","iopub.status.idle":"2023-02-26T16:51:31.174840Z","shell.execute_reply":"2023-02-26T16:51:31.173921Z","shell.execute_reply.started":"2023-02-26T16:51:31.128377Z"},"trusted":true},"outputs":[],"source":["# class Head(nn.Module):\n","#     \"\"\" one head of self-attention \"\"\"\n","\n","#     def __init__(self, n_embd, head_size, dropout):\n","#         super().__init__()\n","#         self.key = nn.Linear(n_embd, head_size, bias=False)\n","#         self.query = nn.Linear(n_embd, head_size, bias=False)\n","#         self.value = nn.Linear(n_embd, head_size, bias=False)\n","\n","#         self.dropout = nn.Dropout(dropout)\n","\n","#     def forward(self, x):\n","#         # input of size (batch, time-step, channels)\n","#         # output of size (batch, time-step, head size)\n","#         B,T,C = x.shape\n","#         k = self.key(x)   # (B,T,hs)\n","#         q = self.query(x) # (B,T,hs)\n","#         # compute attention scores (\"affinities\")\n","#         self.wei = q @ k.transpose(-2,-1) * (k.shape[-1] / math.sqrt(k.shape[-2])) # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n","        \n","#         self.wei = F.softmax(self.wei, dim=-1) # (B, T, T)\n","#         self.wei = self.dropout(self.wei)\n","#         # perform the weighted aggregation of the values\n","#         v = self.value(x) # (B,T,hs)\n","#         self.out = self.wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n","#         return self.out\n","\n","# class MultiHeadAttention(nn.Module):\n","#     \"\"\" multiple heads of self-attention in parallel \"\"\"\n","\n","#     def __init__(self, num_heads, n_embd, head_size, dropout):\n","#         super().__init__()\n","#         self.heads = nn.ModuleList([Head(n_embd, head_size, dropout) for _ in range(num_heads)])\n","#         self.proj = nn.Linear(head_size * num_heads, n_embd)\n","#         self.dropout = nn.Dropout(dropout)\n","\n","#     def forward(self, x):\n","#         self.out = torch.cat([h(x) for h in self.heads], dim=-1)\n","#         self.out = self.dropout(self.proj(self.out))\n","#         return self.out\n","\n","# class FeedForward(nn.Module):\n","#     \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n","\n","#     def __init__(self, n_embd, dropout):\n","#         super().__init__()\n","        \n","#         super().__init__()\n","#         self.c_fc    = nn.Linear(n_embd, ffwd_scale * n_embd)\n","#         self.c_proj  = nn.Linear(ffwd_scale * n_embd, n_embd)\n","#         self.dropout = nn.Dropout(dropout)\n","        \n","        \n","#     def forward(self, x):\n","#         x = self.c_fc(x)\n","#         x = nn.ReLU()(x)\n","#         x = self.c_proj(x)\n","#         self.out = self.dropout(x)\n","#         return self.out\n","\n","# class Block(nn.Module):\n","#     \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","#     def __init__(self, num_heads, n_embd, dropout):\n","#         # n_embd: embedding dimension, num_heads: the number of heads we'd like\n","#         super().__init__()\n","#         head_size = n_embd // num_heads\n","#         self.sa = MultiHeadAttention(num_heads, n_embd, head_size, dropout)\n","#         self.ffwd = FeedForward(n_embd, dropout)\n","#         self.ln1 = nn.LayerNorm(n_embd)\n","#         self.ln2 = nn.LayerNorm(n_embd)\n","\n","#     def forward(self, x):\n","#         x = x + self.sa(self.ln1(x))\n","#         self.out = x + self.ffwd(self.ln2(x))\n","#         return self.out\n","    \n","    \n","    \n","# class FeatureExtractor(nn.Module):\n","#     \"\"\" input (B,T,C), output (B, C) \"\"\"\n","#     def __init__(self, n_embd, num_heads, n_layers, dropout=0.2):\n","#         super().__init__()\n","        \n","#         self.net = nn.Sequential(*[Block(num_heads, n_embd, dropout) for _ in range(n_layers)])\n","        \n","#     def forward(self, x):\n","#         x = self.net(x) # (B, T, C)\n","#         self.out = x[:, -1, :] # (B, C)\n","#         return self.out\n"," \n"," \n","    \n","    \n","# class TransformerModel(nn.Module):\n","\n","#     def _init_weights(self, module):\n","        \n","#         init_std = 0.005\n","        \n","#         if isinstance(module, nn.Linear):\n","#             torch.nn.init.normal_(module.weight, mean=0.0, std=init_std)\n","#             if module.bias is not None:\n","#                 torch.nn.init.zeros_(module.bias)\n","#         elif isinstance(module, nn.Embedding):\n","#             torch.nn.init.normal_(module.weight, mean=0.0, std=2*init_std)\n","            \n","#     def __init__(self, n_embd, num_heads, n_layers, dropout=0.2):\n","#         super().__init__()\n","        \n","#         self.n_embd = n_embd\n","#         self.feat_emb = nn.Linear(11, n_embd)\n","#         self.positional_embeddings = nn.Embedding(block_size, n_embd)\n","        \n","#         # feature extractor\n","#         self.features_extractor = FeatureExtractor(2*n_embd, num_heads, n_layers, dropout)\n","        \n","#         # get probabilities for theta and phi\n","#         self.theta_probas_layer = nn.Linear(2*n_embd, num_bins)\n","#         self.phi_probas_layer = nn.Linear(2*n_embd, num_bins)\n","        \n","        \n","#         # weight initialization\n","#         self.apply(self._init_weights)\n","        \n","#         # apply special scaled init to the residual projections, per GPT-2 paper\n","#         for pn, p in self.named_parameters():\n","#             if 'features.net' in pn and pn.endswith('c_proj.weight'):\n","#                 torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * n_layers))\n","#                 print(f\"Changed init of {pn} to 0.02/sqrt(2 * n_layers)\")\n","#             if 'proj3d' and pn.endswith('c_proj.weight'):\n","#                 torch.nn.init.normal_(p, mean=0.0, std=1/math.sqrt(n_embd))\n","#                 print(f\"Changed init of {pn} to 1/sqrt(n_embd+7)\")\n","        \n","#         # set weights of feat_emb linear layer to std of 1 / sqrt(n_embd)\n","#         torch.nn.init.normal_(self.feat_emb.weight, mean=0.0, std=0.1/math.sqrt(n_embd))\n","        \n","\n","#     def forward(self, X, targets=None, activation=None):\n","        \n","#         # X = {\n","#         #     \"xyz_avg\": xyz_avg_batch,\n","#         #     \"xyz\": xyz_batch,\n","#         #     \"time\": time_batch,\n","#         #     \"charge\": charge_batch,\n","#         #     \"charge_clipped\": charge_clipped_batch,\n","#         #     \"auxiliary\": auxiliary_batch,\n","#         #     \"has_event\": has_event_batch,\n","#         # }\n","        \n","#         xyz_avg, xyz, time, charge, charge_clipped, auxiliary, has_event = X[\"xyz_avg\"], X[\"xyz\"], X[\"time\"], X[\"charge\"], X[\"charge_clipped\"], X[\"auxiliary\"], X[\"has_event\"]\n","        \n","#         x = torch.cat([xyz_avg, xyz, time.unsqueeze(-1), charge.unsqueeze(-1), charge_clipped.unsqueeze(-1), auxiliary.unsqueeze(-1), has_event.unsqueeze(-1)], dim=-1)\n","        \n","        \n","        \n","        \n","#         B, T, _ = x.shape\n","#         x_flat = x.view(B * T, 11)\n","#         x = self.feat_emb(x_flat) \n","#         self.input_embedding = x.view(B, T, self.n_embd)\n","        \n","#         self.pos_embd = self.positional_embeddings(torch.arange(T, device=self.input_embedding.device))\n","        \n","        \n","#         # combine the embeddings\n","#         # x = self.input_embedding + self.pos_embd\n","#         # concatenate the embeddings\n","#         x = torch.cat([self.input_embedding, self.pos_embd.unsqueeze(0).repeat(B, 1, 1)], dim=-1)\n","        \n","        \n","        \n","        \n","#         # get features\n","#         self.features = self.features_extractor(x) # (B, C)\n","\n","        \n","        \n","#         # matrix multiply the features with the projection matrix: (B, C) @ (C, 1) -> (B, 1)\n","            \n","    \n","#         # get probabilities for theta and phi\n","#         theta_preprobas = self.theta_probas_layer(self.features) # (B, n_b)\n","#         phi_preprobas = self.phi_probas_layer(self.features) # (B, n_b)\n","        \n","#         theta_probas = torch.softmax(theta_preprobas, dim=1) # (B, n_b)\n","#         phi_probas = torch.softmax(phi_preprobas, dim=1) # (B, n_b)\n","        \n","        \n","#         theta_pred = np.pi * torch.argmax(theta_probas, dim=1) / num_bins # (B)\n","#         phi_pred = 2 * np.pi * torch.argmax(phi_probas, dim=1) / num_bins # (B)\n","        \n","        \n","        \n","#         if targets is None:\n","#             loss = None\n","#             loss_angular = None\n","#         else: \n","#             # Get the angle theta and phi from the 3D vector\n","#             phi_target = targets[:, 0]\n","#             theta_target = targets[:, 1]\n","            \n","            \n","            \n","#             losses_angular = angular_dist_score(phi_target, theta_target, phi_pred, theta_pred)\n","#             # losses_angular = angular_dist_score(phi_target, theta_target, phi, theta)\n","#             # loss_angular = torch.sum(event_size * losses_angular) / torch.sum(event_size)\n","#             loss_angular = torch.mean(losses_angular)\n","            \n","            \n","            \n","            \n","#             # construct the phi_target_probability and theta_target_probability: these are one-hot vectors with the same shape as phi_probas and theta_probas, with 1 at the position of \n","#             theta_target = theta_target / np.pi\n","#             theta_target = theta_target * num_bins\n","#             theta_target = theta_target.long()\n","#             theta_target = torch.nn.functional.one_hot(theta_target, num_classes=num_bins)\n","            \n","#             phi_target = phi_target / (2*np.pi)\n","#             phi_target = phi_target * num_bins\n","#             phi_target = phi_target.long()\n","#             phi_target = torch.nn.functional.one_hot(phi_target, num_classes=num_bins)\n","            \n","            \n","\n","#             # loss is sum of the cross entropy of the predicted probabilities and the target probabilities\n","#             eps = 1e-8\n","#             loss_theta = torch.mean(-torch.sum(torch.log(theta_probas+eps)*theta_target, axis=-1))\n","#             loss_phi = torch.mean(-torch.sum(torch.log(phi_probas+eps)*phi_target, axis=-1))\n","#             loss = loss_theta + loss_phi\n","\n","            \n","            \n","            \n","        \n","#         return (x, loss), (theta_pred, phi_pred, loss_angular)"]},{"cell_type":"code","execution_count":124,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:31.184950Z","iopub.status.busy":"2023-02-26T16:51:31.182000Z","iopub.status.idle":"2023-02-26T16:51:31.812928Z","shell.execute_reply":"2023-02-26T16:51:31.812017Z","shell.execute_reply.started":"2023-02-26T16:51:31.184916Z"},"trusted":true},"outputs":[],"source":["# model = TransformerModel(n_embd, num_heads, n_layers, dropout)\n","# # load \"model_init.pth\"\n","# model.load_state_dict(torch.load('model-init.pth'))\n","# model = model.to(device)\n","# # print the number of parameters in the model\n","# print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n","\n","# # freeze bias terms\n","# # for name, param in model.named_parameters():\n","# #     if 'bias' in name:\n","# #         param.requires_grad = False"]},{"cell_type":"code","execution_count":125,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:31.819497Z","iopub.status.busy":"2023-02-26T16:51:31.816887Z","iopub.status.idle":"2023-02-26T16:51:32.034788Z","shell.execute_reply":"2023-02-26T16:51:32.033974Z","shell.execute_reply.started":"2023-02-26T16:51:31.819448Z"},"trusted":true},"outputs":[],"source":["\n","# def print_params(model):\n","#     print(\"looping over model params\")\n","#     for name, param in model.named_parameters():\n","#         m, s = torch.mean(param), torch.std(param)\n","#         if s > 0.04 or m > 0.04:\n","#             print(f'{name}: {m:.4f} +/- {s:.4f}')\n","#     print(\"loop finished\")\n","\n","# # print_params(model)"]},{"cell_type":"code","execution_count":127,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:32.041548Z","iopub.status.busy":"2023-02-26T16:51:32.038960Z","iopub.status.idle":"2023-02-26T16:51:32.298353Z","shell.execute_reply":"2023-02-26T16:51:32.297278Z","shell.execute_reply.started":"2023-02-26T16:51:32.041511Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["NeutrinoDetection torch.Size([64, 96, 11])\n"]}],"source":["# X, y = data_loader.get_xy(\"train\")\n","# out = model(X, y)\n","\n","# # print(torch.mean(x), torch.std(x))\n","# # print(\"x[0].shape, x[1].shape\", x[0].shape, x[1].shape)"]},{"cell_type":"code","execution_count":451,"metadata":{},"outputs":[],"source":["# plt.hist(out.detach().cpu().numpy().flatten(), bins=100, density=True, label=\"inp_embedding\", alpha=0.5);"]},{"cell_type":"code","execution_count":452,"metadata":{},"outputs":[],"source":["# plt.hist(model.features_extractor.net[0].sa.heads[0].wei.detach().cpu().numpy().flatten(), bins=100);"]},{"cell_type":"code","execution_count":453,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:32.302218Z","iopub.status.busy":"2023-02-26T16:51:32.301820Z","iopub.status.idle":"2023-02-26T16:51:32.425757Z","shell.execute_reply":"2023-02-26T16:51:32.424695Z","shell.execute_reply.started":"2023-02-26T16:51:32.302184Z"},"trusted":true},"outputs":[],"source":["# plt.hist(out[0].detach().cpu().numpy().flatten(), bins=100, density=True, label=\"inp_embedding\", alpha=0.5);\n","# plt.hist(out[1].detach().cpu().numpy().flatten(), bins=100, density=True, label=\"pos_embedding\", alpha=0.5);\n","# plt.ylim(0, 2000)\n","# plt.legend()\n","# # "]},{"cell_type":"code","execution_count":454,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:32.427826Z","iopub.status.busy":"2023-02-26T16:51:32.427410Z","iopub.status.idle":"2023-02-26T16:51:32.644056Z","shell.execute_reply":"2023-02-26T16:51:32.642947Z","shell.execute_reply.started":"2023-02-26T16:51:32.427787Z"},"trusted":true},"outputs":[],"source":["# %time x = model(X, y)"]},{"cell_type":"code","execution_count":455,"metadata":{},"outputs":[],"source":["# %timeit X, y = data_loader.get_xy(\"train\")"]},{"cell_type":"code","execution_count":456,"metadata":{},"outputs":[],"source":["# %timeit x = model(X, y)"]},{"cell_type":"code","execution_count":457,"metadata":{},"outputs":[],"source":["# CPU:\n","# 163 ms  for loading data, 68ms for model forward pass!!\n","\n","# GPU:\n","# 163 ms  for loading data, 15ms for model forward pass!!\n","\n","# You should preload"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":458,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:32.653443Z","iopub.status.busy":"2023-02-26T16:51:32.653152Z","iopub.status.idle":"2023-02-26T16:51:32.659362Z","shell.execute_reply":"2023-02-26T16:51:32.658269Z","shell.execute_reply.started":"2023-02-26T16:51:32.653417Z"},"trusted":true},"outputs":[],"source":["# start a new wandb run to track this script\n","if LOG_WANDB:\n","    # from kaggle_secrets import UserSecretsClient\n","    # user_secrets = UserSecretsClient()\n","    # secret_value = user_secrets.get_secret(\"wandb_key\")\n","    \n","    wandb.login(key=\"df71c3860e28082a4ef9322a8970ab548124177e\")\n","    \n","    wandb.init(\n","        # set the wandb project where this run will be logged\n","        project=\"neutrino-detection\",\n","\n","        # track hyperparameters and run metadata\n","        config={\n","        \"n_layers\":n_layers,\n","        \"num_heads\":num_heads\n","        }\n","    )\n","    "]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 9/9 [00:03<00:00,  2.97it/s]\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1440x720 with 9 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# # create a PyTorch optimizer\n","# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","# best_loss_angular = 1e10\n","# warmup_steps = 9\n","\n","# # make a figure of (warmup_steps//10, 10) subplots\n","# fig, axs = plt.subplots(warmup_steps//3, 3, figsize=(20, 10))\n","# # set vertical and horizontal space between subplots\n","# fig.subplots_adjust(hspace=0.5, wspace=0.5)\n","\n","\n","# for iter in tqdm(range(warmup_steps)):\n","\n","        \n","#     X, y = data_loader.get_xy('train')\n","\n","#     # evaluate the loss\n","#     (x, loss), (theta, phi, loss_angular) = model(X, y)\n","#     optimizer.zero_grad(set_to_none=True)\n","#     loss.backward()\n","    \n","#     # # clip the gradients    \n","#     # if grad_clip:\n","#     #     torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_val)\n","    \n","    \n","#     grad_magnitudes = []\n","#     for param in model.parameters():\n","#         if param.grad is not None:\n","#             grad_magnitudes.append(param.grad.abs().detach().cpu().numpy().flatten())\n","    \n","    \n","#     optimizer.step()\n","    \n","#     grad_magnitudes = np.abs(np.concatenate(grad_magnitudes))\n","#     grad_magnitudes = grad_magnitudes[grad_magnitudes > 0]\n","#     # grad_magnitudes = grad_magnitudes[grad_magnitudes<grad_clip_val]\n","    \n","#     # plot plt.hist of grad_magnitudes on the iter-th subplot\n","#     axs[iter//3, iter%3].hist(np.log10(grad_magnitudes), bins=100)\n","#     # set title to iter\n","#     axs[iter//3, iter%3].set_title(iter)\n","    \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T16:51:32.661428Z","iopub.status.busy":"2023-02-26T16:51:32.660821Z","iopub.status.idle":"2023-02-26T16:55:18.707639Z","shell.execute_reply":"2023-02-26T16:55:18.706038Z","shell.execute_reply.started":"2023-02-26T16:51:32.661393Z"},"trusted":true},"outputs":[],"source":["\n","# create a PyTorch optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","best_loss_angular = 1e10\n","total_loss = 0\n","total_loss_angular = 0\n","\n","\n","for iter in tqdm(range(max_iters)):\n","\n","\n","\n","    if iter % gradient_accumulation_steps ==  0 :\n","        optimizer.zero_grad(set_to_none=True)\n","        total_loss *= 1 / gradient_accumulation_steps\n","        total_loss_angular *= 1 / gradient_accumulation_steps\n","        print(f\"step {iter}: train distance loss {total_loss:.4f}, train angular loss {total_loss_angular:.4f} \")\n","        if LOG_WANDB and iter > 0 and iter % print_each == 0:\n","            wandb.log({\"dis_loc\": total_loss,\n","                        \"ang_loc\": total_loss_angular\n","                        })\n","            # wandb.log({\"model\": model.state_dict()})\n","        total_loss = 0.\n","        total_loss_angular = 0.\n","    if iter % print_model_each == 0:\n","        indx = iter // print_model_each\n","        torch.save(model.state_dict(), f'model_last_overfit_on_batch_{indx}.pth')  \n","    \n","    \n","    \n","    X, y = data_loader.get_xy('train')\n","    (x, loss), (theta, phi, loss_angular) = model(X, y)\n","\n","    total_loss += loss.item()\n","    total_loss_angular += loss_angular.item()\n","    loss.backward()\n","    \n","    \n","        \n","    # if grad_clip:\n","    #     torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_val)\n","    \n","\n","    # Update the weights every gradient_accumulation_steps batches\n","    if iter % gradient_accumulation_steps == gradient_accumulation_steps - 1:\n","        optimizer.step()\n","    \n","    \n","\n","if LOG_WANDB:\n","    wandb.finish()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-02-26T16:55:18.708985Z","iopub.status.idle":"2023-02-26T16:55:18.709726Z","shell.execute_reply":"2023-02-26T16:55:18.709489Z","shell.execute_reply.started":"2023-02-26T16:55:18.709465Z"},"trusted":true},"outputs":[],"source":["# torch.save(model.state_dict(), 'model.pth')"]},{"cell_type":"markdown","metadata":{},"source":["# Make predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-02-26T16:55:18.711181Z","iopub.status.idle":"2023-02-26T16:55:18.711905Z","shell.execute_reply":"2023-02-26T16:55:18.711677Z","shell.execute_reply.started":"2023-02-26T16:55:18.711652Z"},"trusted":true},"outputs":[],"source":["# model.eval()\n","\n","# batch_size = 64\n","# predictions = []\n","# for i in range(0, len(df), batch_size):\n","#     first_pulse_indices = df[\"first_pulse_index\"][i:i+batch_size].tolist()\n","#     last_pulse_indices = df[\"last_pulse_index\"][i:i+batch_size].tolist()\n","\n","#     # preprocessed data as tensors\n","#     preprocessed_data = [data_loader.get_single_event(first_pulse_index, last_pulse_index, 'eval') for first_pulse_index, last_pulse_index in zip(first_pulse_indices, last_pulse_indices)]\n","\n","#     # create batch of preprocessed data\n","#     xyz = torch.stack([data[\"xyz\"] for data in preprocessed_data])\n","#     time = torch.stack([data[\"time\"] for data in preprocessed_data])\n","#     charge = torch.stack([data[\"charge\"] for data in preprocessed_data])\n","    \n","#     xyz = xyz.to(device)\n","#     time = time.to(device)\n","#     charge = charge.to(device)\n","\n","#     # make predictions\n","#     with torch.no_grad():\n","#         (x, _), (theta, phi, _) = model(xyz, time, charge)\n","    \n","    \n","#     theta_predictions = theta.detach().cpu().numpy()\n","#     phi_predictions = phi.detach().cpu().numpy()\n","    \n","#     print(theta_predictions, phi_predictions)\n","#     pred = np.array([theta_predictions, phi_predictions])\n","    \n","#     # predictions.append(pred.T.tolist()[)\n","    \n","\n","# print(predictions)\n","# # df[\"prediction\"] = predictions\n","# # df[\"azimuth\"] = df[\"prediction\"].apply(lambda x: x[0])\n","# # df[\"zenith\"] = df[\"prediction\"].apply(lambda x: x[1])\n","\n","# # event_id,azimuth,zenith\n","# # df = df[[\"event_id\", \"azimuth\", \"zenith\"]]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-02-26T16:55:18.713419Z","iopub.status.idle":"2023-02-26T16:55:18.714188Z","shell.execute_reply":"2023-02-26T16:55:18.713929Z","shell.execute_reply.started":"2023-02-26T16:55:18.713905Z"},"trusted":true},"outputs":[],"source":["# df = df.sort_values([\"event_id\"])\n","# df.to_csv('submission.csv', index=False)\n","# df"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"vscode":{"interpreter":{"hash":"4dbc9917bcaa9a9fa434c727723b90f93ecc3435121eacd019fcd02c268a833c"}}},"nbformat":4,"nbformat_minor":4}
